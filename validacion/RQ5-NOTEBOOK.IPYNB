{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fdd9499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todas las dependencias están instaladas correctamente.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import textstat\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import scipy\n",
    "import nltk\n",
    "import spacy\n",
    "import sklearn\n",
    "import jinja2\n",
    "import faiss\n",
    "import chromadb\n",
    "import torch\n",
    "\n",
    "print(\"Todas las dependencias están instaladas correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dade0fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jorge\\Desktop\\TFG\\ServicioFlaskGPT\\.venv\\Scripts\\python.exe\n",
      "pandas 2.2.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from textstat import textstat\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import sys, pandas, textstat, csv, pathlib\n",
    "print(sys.executable)\n",
    "print(\"pandas\", pandas.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed40091d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jorge\\Desktop\\TFG\\ServicioFlaskGPT\\.venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1696f9ec",
   "metadata": {},
   "source": [
    "CASO PARA REQUISITOS DEL EXPERTO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9757d6db",
   "metadata": {},
   "source": [
    "CALCULO DE MEDIAS Y DEMAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95b992d",
   "metadata": {},
   "source": [
    "COSAS DEL NOTEBOOK ANTERIOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb71bfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/quick_scan_rege.csv\", sep=';', quotechar='\"')\n",
    "print(df.head(3))\n",
    "print(df.shape)        # debería dar (155, 4)\n",
    "\n",
    "\n",
    "\n",
    "# Verificar que el modelo de spaCy esté instalado\n",
    "import spacy\n",
    "try:\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    print(\"Modelo 'en_core_web_sm' cargado correctamente.\")\n",
    "except OSError:\n",
    "    print(\"Error: Modelo 'en_core_web_sm' no encontrado. Instálalo con 'python -m spacy download en_core_web_sm'\")\n",
    "    raise\n",
    "\n",
    "# Preparar modelo y cargar módulos\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "\n",
    "# Cargar el archivo CSV desde la subcarpeta data\n",
    "df = pd.read_csv('data/req_ia/quick_scan_template.csv')  # Ajusta la ruta si es necesario\n",
    "requisitos = df['descripcion'].tolist()  # Usamos solo la columna 'descripcion' para embeddings\n",
    "\n",
    "# Mostrar los primeros 5 requisitos de forma clara\n",
    "print(\"Primeros 5 requisitos cargados:\")\n",
    "for i, req in enumerate(requisitos[:5], 1):  # Mostrar solo los primeros 5\n",
    "    print(f\"{i}. {req}\")\n",
    "\n",
    "# Contar el número total de requisitos (excluyendo el encabezado)\n",
    "total_requisitos = len(df)  # pandas ya excluye el encabezado al contar las filas\n",
    "print(f\"\\nTotal de requisitos procesados: {total_requisitos}\")\n",
    "\n",
    "\n",
    "\n",
    "# Generar embeddings para los requisitos\n",
    "embeddings = model.encode(requisitos, convert_to_tensor=True)\n",
    "print(f\"Forma de los embeddings: {embeddings.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "# Calcular la matriz de similitud coseno\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity_matrix = cosine_similarity(embeddings.cpu().numpy())\n",
    "print(\"Matriz de similitud:\")\n",
    "print(similarity_matrix)\n",
    "\n",
    "# Guardar la matriz de similitud como archivo .npy (formato binario de NumPy)\n",
    "np.save('rq5/similarity_matrix.npy', similarity_matrix)\n",
    "print(\"Matriz de similitud guardada en 'similarity_matrix.npy'\")\n",
    "\n",
    "# Opcional: Guardar como CSV para inspección manual\n",
    "pd.DataFrame(similarity_matrix).to_csv('rq5/similarity_matrix.csv', index=False)\n",
    "print(\"Matriz de similitud también guardada en 'similarity_matrix.csv'\")\n",
    "\n",
    "\n",
    "# Identificar pares con alta similitud (por ejemplo, >0.7)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cargar la matriz de similitud desde el archivo CSV\n",
    "similarity_matrix = pd.read_csv('rq5/similarity_matrix.csv').values  # Convierte el CSV a un array NumPy\n",
    "print(\"Matriz de similitud cargada (forma:\", similarity_matrix.shape, \")\")\n",
    "\n",
    "# Cargar los requisitos originales desde el CSV\n",
    "df = pd.read_csv('data/req_ia/quick_scan_template.csv')\n",
    "requisitos = df['descripcion'].tolist()\n",
    "print(\"Requisitos cargados:\", len(requisitos))\n",
    "\n",
    "# Crear una lista de pares con alta similitud\n",
    "high_similarity_pairs = []\n",
    "for i in range(len(requisitos)):\n",
    "    for j in range(i + 1, len(requisitos)):  # Evitar comparar un requisito consigo mismo (i != j)\n",
    "        if similarity_matrix[i][j] > 0.7:  # Umbral ajustable (0.7 como ejemplo)\n",
    "            high_similarity_pairs.append({\n",
    "                'Req_1_ID': df['requerimiento_id'][i],  # ID del primer requisito\n",
    "                'Req_1': requisitos[i],\n",
    "                'Req_2_ID': df['requerimiento_id'][j],  # ID del segundo requisito\n",
    "                'Req_2': requisitos[j],\n",
    "                'Similarity': similarity_matrix[i][j]\n",
    "            })\n",
    "\n",
    "# Convertir a DataFrame y guardar\n",
    "if high_similarity_pairs:\n",
    "    df_high_similarity = pd.DataFrame(high_similarity_pairs)\n",
    "    df_high_similarity.to_csv('rq5/high_similarity_pairs.csv', index=False)\n",
    "    print(\"Pares con alta similitud guardados en 'rq5/high_similarity_pairs.csv':\")\n",
    "    print(df_high_similarity)\n",
    "\n",
    "    # Mostrar los 3 pares con mayor similitud\n",
    "    print(\"\\nTop 3 pares con mayor similitud:\")\n",
    "    top_3_pairs = df_high_similarity.sort_values(by='Similarity', ascending=False).head(3)\n",
    "    print(top_3_pairs)\n",
    "else:\n",
    "    print(\"No se encontraron pares con similitud mayor a 0.7.\")\n",
    "\n",
    "\n",
    "##CELDA PARA VISUALIZACION DE LA MATRIZ DE SIMILITUD\n",
    "import numpy as np\n",
    "\n",
    "# Cargar la matriz guardada\n",
    "similarity_matrix = np.load('rq5/similarity_matrix.npy')\n",
    "print(\"Forma de la matriz:\", similarity_matrix.shape)\n",
    "print(\"Primeros 5x5 elementos:\")\n",
    "print(similarity_matrix[:5, :5])  # Muestra solo una parte para no saturar\n",
    "\n",
    "\n",
    "# Índice de legibilidad\n",
    "import textstat\n",
    "def get_legibility_score(text):\n",
    "    return textstat.flesch_reading_ease(text)\n",
    "\n",
    "df['legibility_score'] = df['descripcion'].apply(get_legibility_score)\n",
    "print(\"Puntuaciones de legibilidad:\")\n",
    "print(df[['requerimiento_id', 'descripcion', 'legibility_score']])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Detectar términos ambiguos\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "def detect_ambiguous_terms(text):\n",
    "    doc = nlp(text)\n",
    "    ambiguous_terms = [token.text for token in doc if token.text.lower() in ['fast', 'quick', 'secure', 'efficient']]\n",
    "    return ambiguous_terms\n",
    "\n",
    "\n",
    "\n",
    "df['ambiguous_terms'] = df['descripcion'].apply(detect_ambiguous_terms)\n",
    "print(\"Términos ambiguos:\")\n",
    "print(df[['requerimiento_id', 'descripcion', 'ambiguous_terms']])\n",
    "\n",
    "# Guardar resultados\n",
    "df.to_csv('checklist_with_analysis.csv', index=False)\n",
    "print(\"Análisis guardado en checklist_with_analysis.csv\")\n",
    "\n",
    "\n",
    "##Enfoque final con simlitud entre otros requsitos y legibilidad para decidir calidad de cada requisito\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cargar la matriz de similitud desde el archivo CSV\n",
    "similarity_matrix = pd.read_csv('rq5/similarity_matrix.csv').values  # Convierte el CSV a un array NumPy\n",
    "print(\"Matriz de similitud cargada (forma:\", similarity_matrix.shape, \")\")\n",
    "\n",
    "# Cargar los requisitos originales desde el CSV\n",
    "df_requisitos = pd.read_csv('rq5/checklist_with_analysis.csv')\n",
    "requisitos = df_requisitos['descripcion'].tolist()\n",
    "requerimiento_ids = df_requisitos['requerimiento_id'].tolist()\n",
    "print(\"Requisitos cargados:\", len(requisitos))\n",
    "\n",
    "# Calcular la similitud máxima para cada requisito\n",
    "similitud_maxima_list = []\n",
    "for i in range(len(requisitos)):\n",
    "    max_sim = 0.0\n",
    "    similar_id_idx = None\n",
    "    for j in range(len(requisitos)):\n",
    "        if i != j:  # Evitar comparar un requisito consigo mismo\n",
    "            if similarity_matrix[i][j] > max_sim:\n",
    "                max_sim = similarity_matrix[i][j]\n",
    "                similar_id_idx = j\n",
    "    similar_id = requerimiento_ids[similar_id_idx] if similar_id_idx is not None else \"N/A\"\n",
    "    similitud_maxima_list.append(f\"{max_sim:.2f}-{similar_id}\")\n",
    "\n",
    "# Añadir la columna de similitud máxima al DataFrame\n",
    "df_requisitos['similitud_maxima'] = similitud_maxima_list\n",
    "\n",
    "# Seleccionar solo las columnas requeridas\n",
    "df_output = df_requisitos[['requerimiento_id', 'descripcion', 'legibility_score', 'similitud_maxima']]\n",
    "\n",
    "# Guardar el resultado en un nuevo CSV\n",
    "df_output.to_csv('rq5/requisitos_analisis_simiYlegi.csv', index=False)\n",
    "print(\"CSV generado como 'rq5/requisitos_analisis_simiYlegi.csv' con similitud máxima y puntuación de legibilidad.\")\n",
    "\n",
    "##PROCESO DE VALIDACION REQUISITOS EXPERTO\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Leer el archivo CSV con coma como separador y comillas como quotechar\n",
    "df = pd.read_csv(\"data/req_human/checklist_human.csv\", sep=',', quotechar='\"')\n",
    "print(df.head(3))\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "# Cargar el archivo CSV desde la subcarpeta data\n",
    "df = pd.read_csv('data/req_human/checklist_human.csv')  # Ajusta la ruta si es necesario\n",
    "requisitos_ex = df['Descripción'].tolist()  # Usamos solo la columna 'descripcion' para embeddings\n",
    "\n",
    "# Mostrar los primeros 5 requisitos de forma clara\n",
    "print(\"Primeros 5 requisitos cargados:\")\n",
    "for i, req in enumerate(requisitos_ex[:5], 1):  # Mostrar solo los primeros 5\n",
    "    print(f\"{i}. {req}\")\n",
    "\n",
    "# Contar el número total de requisitos (excluyendo el encabezado)\n",
    "total_requisitos_ex = len(df)  # pandas ya excluye el encabezado al contar las filas\n",
    "print(f\"\\nTotal de requisitos procesados: {total_requisitos_ex}\")\n",
    "\n",
    "\n",
    "# Generar embeddings para los requisitos\n",
    "embeddings = model.encode(requisitos_ex, convert_to_tensor=True)\n",
    "print(f\"Forma de los embeddings: {embeddings.shape}\")\n",
    "\n",
    "# Calcular la matriz de similitud coseno\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity_matrix_ex = cosine_similarity(embeddings.cpu().numpy())\n",
    "print(\"Matriz de similitud requisitos del experto:\")\n",
    "print(similarity_matrix_ex)\n",
    "\n",
    "# Guardar la matriz de similitud como archivo .npy (formato binario de NumPy)\n",
    "np.save('data/req_human/results/similarity_matrix_ex.npy', similarity_matrix_ex)\n",
    "print(\"Matriz de similitud guardada en 'similarity_matrix_ex.npy'\")\n",
    "\n",
    "# Opcional: Guardar como CSV para inspección manual\n",
    "pd.DataFrame(similarity_matrix_ex).to_csv('data/req_human/results/similarity_matrix_ex.csv', index=False)\n",
    "print(\"Matriz de similitud también guardada en 'similarity_matrix_ex.csv'\")\n",
    "print(\"Forma de la matriz:\", similarity_matrix_ex.shape)\n",
    "\n",
    "##UNA VEZ TENEMOS LA MATRIZ DE SIMILITUD PARA LOS REQUISITOS DEL EXPERTO \n",
    "##PASAMOS A CALCULAR LOS PARES MAS SIMILARES DE DICHA MATRIZ \n",
    "##FUSIONARLO CON EL CALCULO DE LA LEGIBILIDAD\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import textstat\n",
    "\n",
    "# Cargar la matriz de similitud desde el archivo .npy (más precisa que CSV)\n",
    "similarity_matrix = np.load('data/req_human/results/similarity_matrix_ex.npy')\n",
    "print(\"Matriz de similitud cargada (forma:\", similarity_matrix.shape, \")\")\n",
    "\n",
    "# Cargar los requisitos originales desde el CSV de los expertos\n",
    "df = pd.read_csv('data/req_human/checklist_human.csv')\n",
    "requisitos = df['Descripción'].tolist()\n",
    "requerimiento_ids = df['ID'].tolist()\n",
    "print(\"Requisitos cargados:\", len(requisitos))\n",
    "\n",
    "# Crear una lista de pares con alta similitud\n",
    "high_similarity_pairs = []\n",
    "for i in range(len(requisitos)):\n",
    "    for j in range(i + 1, len(requisitos)):  # Evitar comparar un requisito consigo mismo\n",
    "        if similarity_matrix[i][j] > 0.7:  # Umbral ajustable (0.7 como ejemplo)\n",
    "            high_similarity_pairs.append({\n",
    "                'Req_1_ID': requerimiento_ids[i],\n",
    "                'Req_1': requisitos[i],\n",
    "                'Req_2_ID': requerimiento_ids[j],\n",
    "                'Req_2': requisitos[j],\n",
    "                'Similarity': similarity_matrix[i][j]\n",
    "            })\n",
    "\n",
    "# Convertir a DataFrame y guardar pares con alta similitud\n",
    "if high_similarity_pairs:\n",
    "    df_high_similarity = pd.DataFrame(high_similarity_pairs)\n",
    "    df_high_similarity.to_csv('data/req_human/results/high_similarity_pairs_ex.csv', index=False)\n",
    "    print(\"Pares con alta similitud guardados en 'data/req_human/results/high_similarity_pairs_ex.csv':\")\n",
    "    print(df_high_similarity)\n",
    "\n",
    "    # Mostrar los 3 pares con mayor similitud\n",
    "    print(\"\\nTop 3 pares con mayor similitud:\")\n",
    "    top_3_pairs = df_high_similarity.sort_values(by='Similarity', ascending=False).head(3)\n",
    "    print(top_3_pairs)\n",
    "else:\n",
    "    print(\"No se encontraron pares con similitud mayor a 0.7.\")\n",
    "\n",
    "# Definir función para calcular el índice de legibilidad (Flesch Reading Ease)\n",
    "def get_legibility_score(text):\n",
    "    \"\"\"\n",
    "    Calcula el índice de legibilidad Flesch Reading Ease para un texto en inglés.\n",
    "    - Retorna un puntaje entre 0 y 100: mayor puntaje = más fácil de leer.\n",
    "    - Basado en la longitud de palabras y oraciones.\n",
    "    \"\"\"\n",
    "    return textstat.flesch_reading_ease(text)\n",
    "\n",
    "# Calcular puntuaciones de legibilidad para cada requisito\n",
    "df['Legibility_Score'] = df['Descripción'].apply(get_legibility_score)\n",
    "print(\"Puntuaciones de legibilidad calculadas:\")\n",
    "print(df[['ID', 'Descripción', 'Legibility_Score']].head())  # Mostrar las primeras 5 filas como ejemplo\n",
    "\n",
    "# Combinar resultados en un DataFrame\n",
    "df_analysis = pd.DataFrame({\n",
    "    'ID': requerimiento_ids,\n",
    "    'Descripción': requisitos,\n",
    "    'Legibility_Score': df['Legibility_Score'].tolist()  # Usar las puntuaciones calculadas\n",
    "})\n",
    "\n",
    "# Añadir la similitud máxima para cada requisito\n",
    "max_similarity = []\n",
    "for i in range(len(requisitos)):\n",
    "    max_sim = 0.0\n",
    "    similar_id_idx = None\n",
    "    for j in range(len(requisitos)):\n",
    "        if i != j and similarity_matrix[i][j] > max_sim:\n",
    "            max_sim = similarity_matrix[i][j]\n",
    "            similar_id_idx = j\n",
    "    similar_id = requerimiento_ids[similar_id_idx] if similar_id_idx is not None else \"N/A\"\n",
    "    max_similarity.append(f\"{max_sim:.2f}-{similar_id}\")\n",
    "\n",
    "df_analysis['Max_Similarity'] = max_similarity\n",
    "\n",
    "# Guardar el análisis combinado\n",
    "df_analysis.to_csv('data/req_human/results/expert_analisis_simiYlegi.csv', index=False)\n",
    "print(\"Análisis combinado guardado en 'data/req_human/results/expert_analisis_simiYlegi.csv'\")\n",
    "\n",
    "##PROCESO DE OBTENCION DE RESULTADOS DEL ANALISIS CRUZADO POR GROK ENTRE MODELO DE NOTEBOOK Y AGENTE DE CHATGPT PARA REQUISITOS DE LA IA\n",
    "# Celda 1: Preprocesar el archivo CSV con corrección de campos\n",
    "import csv\n",
    "\n",
    "# Abrir el archivo original y crear uno nuevo\n",
    "with open('rq5/RQ5-AnalisisCruzadoNote-IA.csv', 'r', encoding='utf-8') as infile, \\\n",
    "     open('rq5/RQ5-AnalisisCruzadoNote-IA_cleaned.csv', 'w', newline='', encoding='utf-8') as outfile:\n",
    "\n",
    "    reader = csv.reader(infile, quotechar='\"', delimiter=',', skipinitialspace=True)\n",
    "    writer = csv.writer(outfile, quotechar='\"', delimiter=',', quoting=csv.QUOTE_ALL, escapechar='\\\\')\n",
    "\n",
    "    # Escribir el encabezado\n",
    "    header = next(reader)\n",
    "    writer.writerow(header)\n",
    "\n",
    "    # Procesar cada línea\n",
    "    for row in reader:\n",
    "        if len(row) < 8:\n",
    "            print(f\"Error: Línea con menos de 8 campos: {row}\")\n",
    "            continue\n",
    "        elif len(row) > 8:\n",
    "            print(f\"Corriendo línea con {len(row)} campos: {row}\")\n",
    "            # Reconstruir los campos de forma dinámica\n",
    "            id_val = row[0]  # ID\n",
    "            req_gen = ' '.join(row[1:4]).strip()  # Unir Requisito generado (hasta 3 elementos si es necesario)\n",
    "            art_fuente = ', '.join(row[4:7]) if len(row) >= 7 else row[4] if len(row) > 4 else ''  # Artículo/Fuente\n",
    "            extraido = row[7] if len(row) > 7 else 'Sí'  # ¿Extraído correctamente?\n",
    "            nivel = row[8] if len(row) > 8 else 'Alta'  # Nivel de fidelidad\n",
    "            tipo_error = row[9] if len(row) > 9 else ''  # Tipo de error\n",
    "            porc_calidad = row[-1]  # Porcentaje de calidad (último elemento)\n",
    "            justif = ' '.join(row[10:-1]).strip() if len(row) > 10 else row[10] if len(row) > 10 else ''  # Justificación/Comentarios\n",
    "\n",
    "            # Asegurarse de que justif no cause error si row[-1] ya fue tomado\n",
    "            if not justif and len(row) > 10:\n",
    "                justif = ' '.join(row[10:]).strip().rsplit(' ', 1)[0]  # Tomar todo menos el último (porc_calidad)\n",
    "\n",
    "            # Escribir la línea corregida\n",
    "            writer.writerow([id_val, req_gen, art_fuente, extraido, nivel, tipo_error, justif, porc_calidad])\n",
    "        else:\n",
    "            writer.writerow(row)\n",
    "\n",
    "print(\"Archivo preprocesado guardado como 'rq5/RQ5-AnalisisCruzadoNote-IA_cleaned.csv'\")\n",
    "\n",
    "##CASO PARA REQUISITOS DEL EXPERTO ###RQ5\n",
    "# Celda: Calcular porcentaje de calidad y generar CSV para requisitos de los expertos con penalización por similitud\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv  # Importado para usar csv.QUOTE_ALL en la escritura del CSV\n",
    "\n",
    "# Leer los archivos\n",
    "# Ajusta las rutas según la ubicación real de tus archivos\n",
    "# df_notebook contiene las evaluaciones de los expertos (Excel)\n",
    "df_notebook_experto = pd.read_excel('data-RQ5/req_human/results/Validacion_Requisitos_Expert.xlsx', sheet_name='Sheet1')\n",
    "# df_llm contiene las métricas de legibilidad y similitud (CSV)\n",
    "df_llm_experto = pd.read_csv('rq5_results/Result_req_Experto/expert_analisis_simiYlegi.csv', quotechar='\"')\n",
    "\n",
    "# Asegurarse de que ambos DataFrames tengan un ID común para el merge\n",
    "# Renombrar columnas en df_notebook\n",
    "df_notebook_experto_cleaned = df_notebook_experto.rename(columns={'ID': 'id'}) if 'ID' in df_notebook_experto.columns else df_notebook_experto\n",
    "# Renombrar columnas en df_llm (corrigiendo de 'requerimiento_id' a 'ID')\n",
    "df_llm_experto_cleaned = df_llm_experto.rename(columns={'ID': 'id', 'Max_Similarity': 'similitud_maxima'}) if 'ID' in df_llm_experto.columns else df_llm_experto\n",
    "\n",
    "# Merge de los DataFrames usando 'id' como clave\n",
    "# Uso de 'how=left' asegura que se conserven todas las filas de df_notebook\n",
    "df_merged = pd.merge(df_notebook_experto_cleaned, df_llm_experto_cleaned, on='id', how='left')\n",
    "\n",
    "# Función para normalizar Legibility_Score a 0-100\n",
    "def normalize_legibility(score):\n",
    "    # Verifica si el score es NaN o no es numérico, devuelve 0 en ese caso\n",
    "    if pd.isna(score) or not isinstance(score, (int, float)):\n",
    "        return 0\n",
    "    # Ajusta negativos a 0 y capta valores a 100 (score + 100, max 100)\n",
    "    return max(0, min(100, score + 100))\n",
    "\n",
    "# Función para calcular el porcentaje de calidad\n",
    "def calculate_quality(row):\n",
    "    # Asigna valor de fidelidad según el nivel reportado\n",
    "    # Alta = 95%, Media = 70%, Baja = 40% (no aplica en datos actuales)\n",
    "    fidelity = 95 if row['Nivel de fidelidad'] == 'Alta' else 70 if row['Nivel de fidelidad'] == 'Media' else 40\n",
    "    \n",
    "    # Normaliza el Legibility_Score si existe en el row\n",
    "    legibility = normalize_legibility(row['Legibility_Score']) if 'Legibility_Score' in row else 0\n",
    "    \n",
    "    # Bono por ausencia de errores: +20% si no hay error, 0% si hay\n",
    "    error_bonus = 20 if pd.isna(row['Tipo de error (si aplica)']) or row['Tipo de error (si aplica)'] == '' else 0\n",
    "    \n",
    "    # Obtiene el texto de justificación o cadena vacía si no existe\n",
    "    justification = row['Justificación/Comentarios'] if 'Justificación/Comentarios' in row else ''\n",
    "    # Bono por justificación: +10% si es positivo, -10% si sugiere mejoras, 0% si neutro\n",
    "    # Incluye \"alineado\", \"compatible\", \"fuerte\", \"coherente\" como positivos\n",
    "    justif_bonus = 10 if any(word in justification.lower() for word in ['positivo', 'clara', 'alineado', 'compatible', 'fuerte', 'coherente']) else \\\n",
    "                   -10 if any(word in justification.lower() for word in ['mejora', 'reformular', 'redundante']) else 0\n",
    "    \n",
    "    # Penalización por similitud: -10% si similitud_maxima > 0.8, 0% en caso contrario\n",
    "    similarity_penalty = -10 if 'similitud_maxima' in row and float(row['similitud_maxima'].split('-')[0]) > 0.8 else 0\n",
    "    \n",
    "    # Cálculo del porcentaje de calidad como promedio de los cinco componentes\n",
    "    quality = (fidelity + legibility + error_bonus + justif_bonus + similarity_penalty) / 5\n",
    "    return round(quality, 2)\n",
    "\n",
    "# Aplicar la función para calcular el porcentaje de calidad a todas las filas\n",
    "df_merged['Porcentaje de calidad'] = df_merged.apply(calculate_quality, axis=1)\n",
    "\n",
    "# Seleccionar y renombrar columnas para el formato deseado\n",
    "# Crea una copia del DataFrame con las columnas relevantes\n",
    "df_result = df_merged[['id', 'Requisito generado', 'Artículo/Fuente', '¿Extraído correctamente?', \n",
    "                       'Nivel de fidelidad', 'Tipo de error (si aplica)', 'Justificación/Comentarios', \n",
    "                       'Porcentaje de calidad']].copy()\n",
    "# Renombra 'id' a 'ID' para consistencia con el formato original\n",
    "df_result = df_result.rename(columns={'id': 'ID'})\n",
    "# Guardar el resultado en un nuevo CSV\n",
    "# Mensaje de confirmación y escritura del archivo con formato citado\n",
    "print(\"OBTENEMOS FICHERO QUE HACIA CRUCE DE DATOS LEGIBILIDAD Y SIMILITUD + COMENTARIOS EXPERTOS CON PENALIZACIÓN POR SIMILITUD\")\n",
    "df_result.to_csv('RESULTADO_RQ5_EXPERTO_ConSimilitud.csv', index=False, quotechar='\"', quoting=csv.QUOTE_ALL, escapechar='\\\\')\n",
    "\n",
    "# Mostrar las primeras filas para verificar los resultados\n",
    "print(df_result.head())\n",
    "\n",
    "# Celda: Analizar resultados_calidad_requisitos.csv y generar gráfico\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Leer el archivo CSV\n",
    "df = pd.read_csv('RESULTADO_RQ5_EXPERTO_ConSimilitud.csv', quotechar='\"')\n",
    "\n",
    "# Calcular métricas básicas\n",
    "media_calidad = df['Porcentaje de calidad'].mean()\n",
    "max_calidad = df['Porcentaje de calidad'].max()\n",
    "min_calidad = df['Porcentaje de calidad'].min()\n",
    "requisito_max = df[df['Porcentaje de calidad'] == max_calidad]['ID'].iloc[0]\n",
    "requisito_min = df[df['Porcentaje de calidad'] == min_calidad]['ID'].iloc[0]\n",
    "\n",
    "# Resumen de calidad general\n",
    "print(\"### Resumen de Calidad de los Requisitos\")\n",
    "print(f\"- Media del porcentaje de calidad: {media_calidad:.2f}%\")\n",
    "print(f\"- Requisito con mayor calidad ({max_calidad}%): {requisito_max}\")\n",
    "print(f\"- Requisito con menor calidad ({min_calidad}%): {requisito_min}\")\n",
    "\n",
    "# Seleccionar los 5 requisitos de mayor y menor calidad\n",
    "top_5 = df.nlargest(5, 'Porcentaje de calidad')[['ID', 'Porcentaje de calidad']]\n",
    "bottom_5 = df.nsmallest(5, 'Porcentaje de calidad')[['ID', 'Porcentaje de calidad']]\n",
    "\n",
    "# Imprimir los datos seleccionados para depuración\n",
    "print(\"Top 5:\", top_5)\n",
    "print(\"Bottom 5:\", bottom_5)\n",
    "\n",
    "# Visualización: Gráfico de barras con los 5 requisitos de mayor y menor calidad\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(top_5['ID'], top_5['Porcentaje de calidad'], color='green', label='Top 5')\n",
    "plt.bar(bottom_5['ID'], bottom_5['Porcentaje de calidad'], color='red', label='Bottom 5')\n",
    "plt.axhline(y=media_calidad, color='blue', linestyle='--', label=f'Media: {media_calidad:.2f}%')\n",
    "plt.title('Top 5 y Bottom 5 Requisitos por Calidad - Requisitos del Experto')\n",
    "plt.xlabel('ID del Requisito')\n",
    "plt.ylabel('Porcentaje de Calidad (%)')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "##CASO PARA CALCULA CALIDAD LOS REQUISITOS DEL AGENTE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv  # Importado para usar csv.QUOTE_ALL en la escritura del CSV\n",
    "\n",
    "# Leer los archivos\n",
    "# Ajusta las rutas según la ubicación real de tus archivos\n",
    "# df_notebook contiene las evaluaciones de los expertos (Excel)\n",
    "df_notebook_agente = pd.read_excel('rq5_results/Validación_Requisitos_Agente.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "# df_llm contiene las métricas de legibilidad y similitud (CSV)\n",
    "df_llm_agente = pd.read_csv('rq5_results/Result_req_Agente/requisitos_analisis_simiYlegi.csv', quotechar='\"')\n",
    "\n",
    "# Renombrar columnas para unificar la clave 'id'\n",
    "df_notebook_agente_cleaned = df_notebook_agente.rename(columns={'ID': 'id'})\n",
    "df_llm_agente_cleaned = df_llm_agente.rename(columns={'requerimiento_id': 'id'})\n",
    "\n",
    "# Merge de los DataFrames usando 'id' como clave\n",
    "# Uso de 'how=left' asegura que se conserven todas las filas de df_notebook\n",
    "df_merged_agente = pd.merge(df_notebook_agente_cleaned, df_llm_agente_cleaned, on='id', how='left')\n",
    "\n",
    "# Función para normalizar Legibility_Score a 0-100\n",
    "def normalize_legibility(score):\n",
    "    # Verifica si el score es NaN o no es numérico, devuelve 0 en ese caso\n",
    "    if pd.isna(score) or not isinstance(score, (int, float)):\n",
    "        return 0\n",
    "    # Ajusta negativos a 0 y capta valores a 100 (score + 100, max 100)\n",
    "    return max(0, min(100, score + 100))\n",
    "\n",
    "# Función para calcular el porcentaje de calidad\n",
    "def calculate_quality(row):\n",
    "    # Asigna valor de fidelidad según el nivel reportado\n",
    "    # Alta = 95%, Media = 70%, Baja = 40% (no aplica en datos actuales)\n",
    "    fidelity = 95 if row['Nivel de fidelidad'] == 'Alta' else 70 if row['Nivel de fidelidad'] == 'Media' else 40\n",
    "    \n",
    "    # Normaliza el Legibility_Score si existe en el row\n",
    "    legibility = normalize_legibility(row['legibility_score']) if 'legibility_score' in row else 0\n",
    "    \n",
    "    # Bono por ausencia de errores: +20% si no hay error, 0% si hay\n",
    "    error_bonus = 20 if pd.isna(row['Tipo de error (si aplica)']) or row['Tipo de error (si aplica)'] == '' else 0\n",
    "    \n",
    "    # Obtiene el texto de justificación o cadena vacía si no existe\n",
    "    justification = row['Justificación/Comentarios'] if 'Justificación/Comentarios' in row else ''\n",
    "    # Bono por justificación: +10% si es positivo, -10% si sugiere mejoras, 0% si neutro\n",
    "    # Incluye \"alineado\", \"compatible\", \"fuerte\", \"coherente\" como positivos\n",
    "    justif_bonus = 10 if any(word in justification.lower() for word in ['positivo', 'clara', 'alineado', 'compatible', 'fuerte', 'coherente']) else \\\n",
    "                   -10 if any(word in justification.lower() for word in ['mejora', 'reformular', 'redundante']) else 0\n",
    "    \n",
    "    # Penalización por similitud: -10% si similitud_maxima > 0.8, 0% en caso contrario\n",
    "    similarity_penalty = -10 if 'similitud_maxima' in row and float(row['similitud_maxima'].split('-')[0]) > 0.8 else 0\n",
    "    \n",
    "    # Cálculo del porcentaje de calidad como promedio de los cinco componentes\n",
    "    quality = (fidelity + legibility + error_bonus + justif_bonus + similarity_penalty) / 5\n",
    "    return round(quality, 2)\n",
    "\n",
    "# Aplicar la función para calcular el porcentaje de calidad a todas las filas\n",
    "df_merged_agente['Porcentaje de calidad'] = df_merged_agente.apply(calculate_quality, axis=1)\n",
    "\n",
    "# Seleccionar y renombrar columnas para el formato deseado\n",
    "# Crea una copia del DataFrame con las columnas relevantes\n",
    "df_result_agente = df_merged_agente[['id', 'Requisito generado', 'Artículo/Fuente', '¿Extraído correctamente?', \n",
    "                       'Nivel de fidelidad', 'Tipo de error (si aplica)', 'Justificación/Comentarios', \n",
    "                       'Porcentaje de calidad']].copy()\n",
    "# Renombra 'id' a 'ID' para consistencia con el formato original\n",
    "df_result_agente = df_result_agente.rename(columns={'id': 'ID'})\n",
    "# Guardar el resultado en un nuevo CSV\n",
    "# Mensaje de confirmación y escritura del archivo con formato citado\n",
    "print(\"OBTENEMOS FICHERO QUE HACIA CRUCE DE DATOS LEGIBILIDAD Y SIMILITUD + COMENTARIOS AGENTE CON PENALIZACIÓN POR SIMILITUD\")\n",
    "df_result_agente.to_csv('RESULTADO_RQ5_AGENTE_ConSimilitud.csv', index=False, quotechar='\"', quoting=csv.QUOTE_ALL, escapechar='\\\\')\n",
    "\n",
    "# Mostrar las primeras filas para verificar los resultados\n",
    "print(df_result_agente.head())\n",
    "\n",
    "\n",
    "# Celda: Analizar resultados_calidad_requisitos.csv y generar gráfico\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Leer el archivo CSV\n",
    "df = pd.read_csv('RESULTADO_RQ5_AGENTE_ConSimilitud.csv', quotechar='\"')\n",
    "\n",
    "# Calcular métricas básicas\n",
    "media_calidad = df['Porcentaje de calidad'].mean()\n",
    "max_calidad = df['Porcentaje de calidad'].max()\n",
    "min_calidad = df['Porcentaje de calidad'].min()\n",
    "requisito_max = df[df['Porcentaje de calidad'] == max_calidad]['ID'].iloc[0]\n",
    "requisito_min = df[df['Porcentaje de calidad'] == min_calidad]['ID'].iloc[0]\n",
    "\n",
    "# Resumen de calidad general\n",
    "print(\"### Resumen de Calidad de los Requisitos\")\n",
    "print(f\"- Media del porcentaje de calidad: {media_calidad:.2f}%\")\n",
    "print(f\"- Requisito con mayor calidad ({max_calidad}%): {requisito_max}\")\n",
    "print(f\"- Requisito con menor calidad ({min_calidad}%): {requisito_min}\")\n",
    "\n",
    "# Seleccionar los 5 requisitos de mayor y menor calidad\n",
    "top_5 = df.nlargest(5, 'Porcentaje de calidad')[['ID', 'Porcentaje de calidad']]\n",
    "bottom_5 = df.nsmallest(5, 'Porcentaje de calidad')[['ID', 'Porcentaje de calidad']]\n",
    "\n",
    "# Imprimir los datos seleccionados para depuración\n",
    "print(\"Top 5:\", top_5)\n",
    "print(\"Bottom 5:\", bottom_5)\n",
    "\n",
    "# Visualización: Gráfico de barras con los 5 requisitos de mayor y menor calidad\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(top_5['ID'], top_5['Porcentaje de calidad'], color='green', label='Top 5')\n",
    "plt.bar(bottom_5['ID'], bottom_5['Porcentaje de calidad'], color='red', label='Bottom 5')\n",
    "plt.axhline(y=media_calidad, color='blue', linestyle='--', label=f'Media: {media_calidad:.2f}%')\n",
    "plt.title('Top 5 y Bottom 5 Requisitos por Calidad - Requisitos del AGENTE')\n",
    "plt.xlabel('ID del Requisito')\n",
    "plt.ylabel('Porcentaje de Calidad (%)')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "##ANALISIS\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Leer los datos reales desde los archivos CSV\n",
    "agente_df = pd.read_csv('rq5_results/Result_req_Agente/high_similarity_pairs_agente.csv')\n",
    "experto_df = pd.read_csv('rq5_results/Result_req_Experto/high_similarity_pairs_experto.csv')\n",
    "\n",
    "# Leer los datos de calidad desde los archivos proporcionados\n",
    "sir_df = pd.read_csv('RESULTADO_RQ5_AGENTE_ConSimilitud.csv')\n",
    "sec_df = pd.read_csv('RESULTADO_RQ5_EXPERTO_ConSimilitud.csv')\n",
    "\n",
    "# 1. Preparar datos para los charts\n",
    "# Distribución de porcentajes de calidad basada en los archivos reales\n",
    "score_ranges = [\"32-35\", \"35-38\", \"38-41\", \"41-44\", \"44-46\"]\n",
    "sec_data = [len(sec_df[(sec_df['Porcentaje de calidad'] >= 32) & (sec_df['Porcentaje de calidad'] < 35)]),\n",
    "            len(sec_df[(sec_df['Porcentaje de calidad'] >= 35) & (sec_df['Porcentaje de calidad'] < 38)]),\n",
    "            len(sec_df[(sec_df['Porcentaje de calidad'] >= 38) & (sec_df['Porcentaje de calidad'] < 41)]),\n",
    "            len(sec_df[(sec_df['Porcentaje de calidad'] >= 41) & (sec_df['Porcentaje de calidad'] < 44)]),\n",
    "            len(sec_df[(sec_df['Porcentaje de calidad'] >= 44) & (sec_df['Porcentaje de calidad'] <= 46)])]\n",
    "sir_data = [len(sir_df[(sir_df['Porcentaje de calidad'] >= 32) & (sir_df['Porcentaje de calidad'] < 35)]),\n",
    "            len(sir_df[(sir_df['Porcentaje de calidad'] >= 35) & (sir_df['Porcentaje de calidad'] < 38)]),\n",
    "            len(sir_df[(sir_df['Porcentaje de calidad'] >= 38) & (sir_df['Porcentaje de calidad'] < 41)]),\n",
    "            len(sir_df[(sir_df['Porcentaje de calidad'] >= 41) & (sir_df['Porcentaje de calidad'] < 44)]),\n",
    "            len(sir_df[(sir_df['Porcentaje de calidad'] >= 44) & (sir_df['Porcentaje de calidad'] <= 46)])]\n",
    "\n",
    "# Sugerencias de mejora (aproximadas, basadas en requisitos con nivel de fidelidad 'Media')\n",
    "improvement_data = {\"Expertos (SEC)\": len(sec_df[sec_df['Nivel de fidelidad'] == 'Media']),\n",
    "                    \"Agente (SIR)\": len(sir_df[sir_df['Nivel de fidelidad'] == 'Media'])}\n",
    "\n",
    "# Distribución de similitudes\n",
    "def get_similarity_distribution(df, group_name):\n",
    "    similarities = df['Similarity'].values\n",
    "    bins = [0.7, 0.75, 0.8, 0.85, 0.9, 1.0]\n",
    "    hist, _ = np.histogram(similarities, bins=bins)\n",
    "    return hist\n",
    "\n",
    "sec_sim_data = get_similarity_distribution(experto_df, \"Expertos (SEC)\")\n",
    "sir_sim_data = get_similarity_distribution(agente_df, \"Agente (SIR)\")\n",
    "similarity_ranges = [\"0.7-0.75\", \"0.75-0.8\", \"0.8-0.85\", \"0.85-0.9\", \"0.9-1.0\"]\n",
    "\n",
    "# 2. Análisis básico con matplotlib\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Chart 1: Distribución de porcentajes de calidad\n",
    "plt.subplot(1, 3, 1)\n",
    "bar_width = 0.35\n",
    "x = np.arange(len(score_ranges))\n",
    "plt.bar(x - bar_width/2, sec_data, bar_width, color='#FF6384', alpha=0.7, label='Expertos (SEC)')\n",
    "plt.bar(x + bar_width/2, sir_data, bar_width, color='#36A2EB', alpha=0.7, label='Agente (SIR)')\n",
    "plt.xlabel('Rango de porcentaje de calidad')\n",
    "plt.ylabel('Número de requisitos')\n",
    "plt.title('Distribución de porcentajes de calidad')\n",
    "plt.xticks(x, score_ranges)\n",
    "plt.legend()\n",
    "\n",
    "# Chart 2: Frecuencia de sugerencias de mejora\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.bar(improvement_data.keys(), improvement_data.values(), color=['#FF6384', '#36A2EB'])\n",
    "plt.title('Frecuencia de sugerencias de mejora')\n",
    "plt.xlabel('Grupo')\n",
    "plt.ylabel('Número de requisitos')\n",
    "\n",
    "# Chart 3: Distribución de similitudes\n",
    "plt.subplot(1, 3, 3)\n",
    "bar_width = 0.35\n",
    "x = np.arange(len(similarity_ranges))\n",
    "plt.bar(x - bar_width/2, sec_sim_data, bar_width, color='#FF6384', alpha=0.7, label='Expertos (SEC)')\n",
    "plt.bar(x + bar_width/2, sir_sim_data, bar_width, color='#36A2EB', alpha=0.7, label='Agente (SIR)')\n",
    "plt.xlabel('Rango de similitud')\n",
    "plt.ylabel('Número de pares')\n",
    "plt.title('Distribución de similitudes entre pares')\n",
    "plt.xticks(x, similarity_ranges)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 3. Resumen estadístico\n",
    "print(\"Estadísticas preliminares:\")\n",
    "print(f\"Expertos (SEC): Número de pares con similitud >0.7: {len(experto_df)}, Promedio similitud: {experto_df['Similarity'].mean():.3f}\")\n",
    "print(f\"Agente (SIR): Número de pares con similitud >0.7: {len(agente_df)}, Promedio similitud: {agente_df['Similarity'].mean():.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
